{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1c76de",
   "metadata": {},
   "source": [
    "# 5、Adam\n",
    "\n",
    "在 Gradient Descent 的基础上，做了如下几个方面的改进：\n",
    "\n",
    "1、梯度方面增加了 momentum，使用累积梯度： $v \\leftarrow \\alpha v + (1 - \\alpha)g$\n",
    "\n",
    "2、同 RMSProp 优化算法一样，对学习率进行优化，使用累积平方梯度： $r \\leftarrow \\lambda r + (1 - \\lambda)g^2$\n",
    "\n",
    "3、偏差纠正： $\\hat{v} = \\frac{v}{1-\\alpha^t}$, $\\hat{r} = \\frac{r}{1-\\lambda^t}$\n",
    "\n",
    "再如上3点改进的基础上，权重更新： $w \\leftarrow w - \\frac{\\eta}{\\sqrt{\\hat{r}+\\delta}} * \\hat{v}$\n",
    "\n",
    "<br>\n",
    "\n",
    "> **<font color=\"green\">| 为啥要偏差纠正</font>**\n",
    ">\n",
    "> 第1次更新时， $v_1 \\leftarrow \\alpha v_0 + (1 - \\alpha)g_1$，由于 $v_0$ 的初始是0，且 $\\alpha$ (即 $\\beta$ )值一般会设置为接近于1，因此 $t$ 较小时， $v$ 的值是偏向于0的\n",
    "\n",
    "```python\n",
    "def adam(learning_rate, beta1, beta2, epsilon, var, grad, m, v, t):\n",
    "    m = beta1 * m + (1 - beta1) * grad\n",
    "    v = beta2 * v + (1 - beta2) * grad * grad\n",
    "    m_hat = m / (1 - beta1 ** t)\n",
    "    v_hat = v / (1 - beta2 ** t)\n",
    "    var = var - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "    return var, m, v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2665e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# ---------------------------\n",
    "# 设置Matplotlib支持中文\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "# ---------------------------\n",
    "\n",
    "def loss_function(x, y):\n",
    "    # f(x) = x_1^2 + 10x_2^2\n",
    "    return x**2 + 10 * y**2\n",
    "\n",
    "# 初始化参数\n",
    "x_start, y_start = 40.0, 20.0\n",
    "# Adam 参数\n",
    "lr = 0.5          # 学习率\n",
    "beta1 = 0.9       # Momentum 参数\n",
    "beta2 = 0.999     # RMSProp 参数\n",
    "epsilon = 1e-8\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "# 1. RMSProp算法 (用于对比)\n",
    "x_rms, y_rms = x_start, y_start\n",
    "r_x, r_y = 0, 0\n",
    "rms_lr = 0.5 \n",
    "decay_rate = 0.9\n",
    "result_rms = [(x_rms, y_rms)]\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    g_x = 2 * x_rms\n",
    "    g_y = 20 * y_rms\n",
    "    \n",
    "    r_x = decay_rate * r_x + (1 - decay_rate) * g_x**2\n",
    "    r_y = decay_rate * r_y + (1 - decay_rate) * g_y**2\n",
    "    \n",
    "    x_rms -= (rms_lr / np.sqrt(r_x + 1e-10)) * g_x\n",
    "    y_rms -= (rms_lr / np.sqrt(r_y + 1e-10)) * g_y\n",
    "    result_rms.append((x_rms, y_rms))\n",
    "\n",
    "# 2. Adagrad算法 (用于对比)\n",
    "x_ada, y_ada = x_start, y_start\n",
    "r_x_ada, r_y_ada = 0, 0\n",
    "ada_lr = 1.5 \n",
    "result_ada = [(x_ada, y_ada)]\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    g_x = 2 * x_ada\n",
    "    g_y = 20 * y_ada\n",
    "    \n",
    "    r_x_ada += g_x ** 2\n",
    "    r_y_ada += g_y ** 2\n",
    "    \n",
    "    x_ada -= (ada_lr / np.sqrt(r_x_ada + 1e-10)) * g_x\n",
    "    y_ada -= (ada_lr / np.sqrt(r_y_ada + 1e-10)) * g_y\n",
    "    result_ada.append((x_ada, y_ada))\n",
    "\n",
    "# 3. Adam算法\n",
    "x_adam, y_adam = x_start, y_start\n",
    "m_x, m_y = 0, 0   # 一阶矩估计 (Momentum)\n",
    "v_x, v_y = 0, 0   # 二阶矩估计 (RMSProp)\n",
    "result_adam = [(x_adam, y_adam)]\n",
    "\n",
    "for t in range(1, num_epochs + 1):\n",
    "    g_x = 2 * x_adam\n",
    "    g_y = 20 * y_adam\n",
    "    \n",
    "    # Update biased first moment estimate\n",
    "    m_x = beta1 * m_x + (1 - beta1) * g_x\n",
    "    m_y = beta1 * m_y + (1 - beta1) * g_y\n",
    "    \n",
    "    # Update biased second raw moment estimate\n",
    "    v_x = beta2 * v_x + (1 - beta2) * g_x**2\n",
    "    v_y = beta2 * v_y + (1 - beta2) * g_y**2\n",
    "    \n",
    "    # Compute bias-corrected first moment estimate\n",
    "    m_hat_x = m_x / (1 - beta1**t)\n",
    "    m_hat_y = m_y / (1 - beta1**t)\n",
    "    \n",
    "    # Compute bias-corrected second raw moment estimate\n",
    "    v_hat_x = v_x / (1 - beta2**t)\n",
    "    v_hat_y = v_y / (1 - beta2**t)\n",
    "    \n",
    "    # Update parameters\n",
    "    x_adam -= lr * m_hat_x / (np.sqrt(v_hat_x) + epsilon)\n",
    "    y_adam -= lr * m_hat_y / (np.sqrt(v_hat_y) + epsilon)\n",
    "    \n",
    "    result_adam.append((x_adam, y_adam))\n",
    "\n",
    "# --- 2D 绘图代码 ---\n",
    "\n",
    "# 提取轨迹\n",
    "x_traj_rms = [p[0] for p in result_rms]\n",
    "y_traj_rms = [p[1] for p in result_rms]\n",
    "\n",
    "x_traj_ada = [p[0] for p in result_ada]\n",
    "y_traj_ada = [p[1] for p in result_ada]\n",
    "\n",
    "x_traj_adam = [p[0] for p in result_adam]\n",
    "y_traj_adam = [p[1] for p in result_adam]\n",
    "\n",
    "# 创建网格 (范围稍微缩小一点，以便看清楚轨迹)\n",
    "X_range = np.arange(-10, 50, 0.5)\n",
    "Y_range = np.arange(-10, 30, 0.5)\n",
    "X, Y = np.meshgrid(X_range, Y_range)\n",
    "Z = loss_function(X, Y)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# 绘制等高线\n",
    "contour = plt.contour(X, Y, Z, levels=50, cmap='viridis', alpha=0.5)\n",
    "plt.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "# 绘制轨迹\n",
    "plt.plot(x_traj_rms, y_traj_rms, 'g--d', label=f'RMSProp', alpha=0.6, markersize=5)\n",
    "plt.plot(x_traj_ada, y_traj_ada, 'b--o', label=f'Adagrad', alpha=0.4, markersize=5)\n",
    "plt.plot(x_traj_adam, y_traj_adam, 'r-D', label=f'Adam', linewidth=2, markersize=5)\n",
    "\n",
    "# 起点终点\n",
    "plt.plot(x_start, y_start, 'ko', markersize=10, label='Start')\n",
    "plt.plot(0, 0, 'k*', markersize=15, label='Optimal (0,0)')\n",
    "\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title(f'Adam vs RMSProp vs Adagrad 优化轨迹对比', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 放大显示 (Zoom In)\n",
    "plt.xlim(-5, 45)\n",
    "plt.ylim(-5, 25)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- 3D 绘图代码 ---\n",
    "\n",
    "# 计算轨迹上的Z值\n",
    "z_traj_rms = [loss_function(p[0], p[1]) for p in result_rms]\n",
    "z_traj_ada = [loss_function(p[0], p[1]) for p in result_ada]\n",
    "z_traj_adam = [loss_function(p[0], p[1]) for p in result_adam]\n",
    "\n",
    "fig = plt.figure(figsize=(14, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制表面\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.3, edgecolor='none')\n",
    "\n",
    "# 绘制轨迹\n",
    "ax.plot(x_traj_rms, y_traj_rms, z_traj_rms, 'g--', linewidth=2, label='RMSProp')\n",
    "ax.plot(x_traj_ada, y_traj_ada, z_traj_ada, 'b--', linewidth=2, label='Adagrad')\n",
    "ax.plot(x_traj_adam, y_traj_adam, z_traj_adam, 'r-', linewidth=3, label='Adam', zorder=10)\n",
    "\n",
    "# 标记\n",
    "ax.scatter([x_start], [y_start], [loss_function(x_start, y_start)], c='k', s=60, label='Start')\n",
    "ax.scatter([0], [0], [0], c='k', marker='*', s=150, label='Optimal')\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('Loss')\n",
    "ax.set_title('3D View: Adam 结合了 Momentum 和 RMSProp 的优势', fontsize=14)\n",
    "ax.view_init(elev=35, azim=130) \n",
    "\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5, label='Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
